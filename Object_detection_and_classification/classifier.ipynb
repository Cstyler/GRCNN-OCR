{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import imageio\n",
    "import torchvision\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision.transforms import transforms\n",
    "# from detector.detect2 import Detector\n",
    "# from detector.productdetector import draw_rectange, put_text\n",
    "from train.dataset import ProductsDataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = \"csv/\"\n",
    "df = pd.read_csv(csv_folder + \"fruits_vegetables_filtered.csv\")\n",
    "products_types_dict = dict(zip(df[\"Материал\"], df[\"Вид\"]))\n",
    "df = pd.read_csv(csv_folder + \"main_products.csv\")\n",
    "products_types_dict_main = dict(zip(df[\"Материал\"], df[\"Classifier\"]))\n",
    "products_types_dict.update(products_types_dict_main)\n",
    "model = \"efficientnet_b3\"\n",
    "num_classes = 211  # TODO read from config\n",
    "model = torchvision.models.__dict__[model](num_classes=num_classes)\n",
    "gpu_flag = 0\n",
    "device = torch.device(\"cuda\" if gpu_flag else \"cpu\")\n",
    "model.load_state_dict(\n",
    "    torch.load(\"train/checkpoint.pth\", map_location=device)[\"model\"]\n",
    ")\n",
    "model.eval()\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")\n",
    "with open(\"dataset/classes.pkl\", \"rb\") as f:\n",
    "    class_to_idx = pickle.load(f)\n",
    "idx_to_cls = {idx: cls for cls, idx in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"dataset/val\")\n",
    "count = 0\n",
    "total = 0\n",
    "with torch.inference_mode():\n",
    "    for d1 in root.iterdir():\n",
    "        for d2 in d1.iterdir():\n",
    "            for d3 in d2.iterdir():\n",
    "                for plu_dir in d3.iterdir():\n",
    "                    for path_obj in plu_dir.iterdir():\n",
    "                        crop = PIL.Image.open(path_obj)\n",
    "                        res = model.forward(torch.unsqueeze(trans(crop), 0))[0].argmax()\n",
    "                        # print(idx_to_cls[int(res)], products_types_dict[int(plu_dir.name)])\n",
    "                        plu = int(plu_dir.name)\n",
    "                        cls = \"Other\" if plu not in products_types_dict else products_types_dict[plu]\n",
    "                        print(cls, idx_to_cls[int(res)])\n",
    "                        # count += int(res) == class_to_idx[cls]\n",
    "                        # total += 1\n",
    "print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
