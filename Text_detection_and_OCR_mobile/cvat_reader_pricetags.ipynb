{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import shutil\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tools.draw_utils import draw_inference\n",
    "from tools.image_utils import is_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_coordinates(box_element):\n",
    "    xmin = int(float(box_element.get('xtl')))\n",
    "    ymin = int(float(box_element.get('ytl')))\n",
    "    xmax = int(float(box_element.get('xbr')))\n",
    "    ymax = int(float(box_element.get('ybr')))\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def parse_cvat(xml_path):\n",
    "    anns = []\n",
    "    \n",
    "    root = etree.parse(xml_path).getroot()\n",
    "\n",
    "    task = root.find('.//task')\n",
    "    task_id = task.find('id').text\n",
    "    task_name = task.find('name').text\n",
    "    \n",
    "    for image_tag in root.iterfind('image'):\n",
    "        image_info = {}\n",
    "        \n",
    "        image_info['filename'] = os.path.basename(image_tag.get('name'))\n",
    "        image_info['task_id'] = task_id\n",
    "        image_info['task_name'] = task_name\n",
    "        image_info['symbols'] = []\n",
    "        image_info['rubs'] = []\n",
    "        image_info['kops'] = []\n",
    "        image_info['price_areas'] = []\n",
    "        image_info['discount_areas'] = []\n",
    "        \n",
    "        for box_tag in image_tag:\n",
    "            if box_tag.tag != 'box':\n",
    "                raise Exception(f'Not box! box: {box_tag.tag}, xml_path: {xml_path}')\n",
    "\n",
    "            label = box_tag.get('label')   \n",
    "            xmin, ymin, xmax, ymax = get_coordinates(box_tag)\n",
    "            \n",
    "            if label in ['Symbol']:\n",
    "                symbol_value = str(box_tag[0].text)\n",
    "                image_info['symbols'].append([symbol_value, xmin, ymin, xmax, ymax])\n",
    "            elif label in ['Roubles']:\n",
    "                image_info['rubs'].append([xmin, ymin, xmax, ymax])\n",
    "            elif label in ['kopecks']:\n",
    "                image_info['kops'].append([xmin, ymin, xmax, ymax])\n",
    "            elif label in ['Price Area']:\n",
    "                image_info['price_areas'].append([xmin, ymin, xmax, ymax])\n",
    "            elif label in ['Discount Area']:\n",
    "                if box_tag[0].get('name') == 'Orientation':\n",
    "                    image_info['discount_areas'].append([box_tag[0].text, xmin, ymin, xmax, ymax])\n",
    "                else:\n",
    "                    raise Exception(f'Unknown attribute name: {box_tag[0].get(\"name\")}, xml_path: {xml_path}')\n",
    "            else:\n",
    "                raise Exception(f'Unknown label! label: \\'{label}\\', xml_path: {xml_path}')\n",
    "\n",
    "        anns.append(image_info)\n",
    "    return anns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLECT ANNOTATIONS AND IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # dataset_dir = '/home/ml/datasets/price_tags/DANONE'\n",
    "# # dataset_dir = '/home/ml/datasets/price_tags/EFKO'\n",
    "# # dataset_dir = '/home/ml/datasets/price_tags/FERRERO'\n",
    "# # dataset_dir = '/home/ml/datasets/price_tags/NESTLE'\n",
    "# # dataset_dir = '/home/ml/datasets/price_tags/SHWARZ'\n",
    "\n",
    "\n",
    "\n",
    "# ann_dir = os.path.join(dataset_dir, 'anns')\n",
    "# img_dir = os.path.join(dataset_dir, 'imgs')\n",
    "\n",
    "\n",
    "# # move annotations\n",
    "# paths = glob.glob(os.path.join(dataset_dir, '**', '*.xml'), recursive=True)\n",
    "# paths = [i for i in paths if not i.startswith(ann_dir)]\n",
    "# paths = [i for i in paths if not i.startswith(img_dir)]\n",
    "# print(f'annotations: {len(paths)}')\n",
    "# for i, p in enumerate(paths, 1):\n",
    "#     os.makedirs(ann_dir, exist_ok=True)\n",
    "#     save_p = os.path.join(ann_dir, f'annotations_{i}.xml')\n",
    "#     os.rename(p, save_p)\n",
    "\n",
    "\n",
    "# # move images\n",
    "# paths = glob.glob(os.path.join(dataset_dir, '**'), recursive=True)\n",
    "# paths = [i for i in paths if is_image(i)]\n",
    "# paths = [i for i in paths if not i.startswith(ann_dir)]\n",
    "# paths = [i for i in paths if not i.startswith(img_dir)]\n",
    "# print(f'images: {len(paths)}')\n",
    "# for p in paths:\n",
    "#     os.makedirs(img_dir, exist_ok=True)\n",
    "#     img_name = os.path.basename(p)\n",
    "#     save_p = os.path.join(img_dir, img_name)\n",
    "#     os.rename(p, save_p)\n",
    "\n",
    "\n",
    "# # delete everything except 'ann_dir' and 'img_dir'\n",
    "# paths = glob.glob(os.path.join(dataset_dir, '*'))\n",
    "# paths.remove(ann_dir)\n",
    "# paths.remove(img_dir)\n",
    "# print(f'delete: {len(paths)}')\n",
    "# for p in paths:\n",
    "#     if os.path.isfile(p):\n",
    "#         os.remove(p)\n",
    "#     else:\n",
    "#         shutil.rmtree(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ AND SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_paths: 1245\n",
      "imgs: 1245\n",
      "anns: 1245\n",
      "\n",
      "FILES NOT FOUND: 0\n",
      "\n",
      "\n",
      "Make unique!\n",
      "unique img_paths: 1245\n",
      "unique imgs: 1245\n",
      "unique anns: 1245\n",
      "\n",
      "\n",
      "Filter empty anns!\n",
      "empty anns: 7\n",
      "img_paths: 1238\n",
      "imgs: 1238\n",
      "anns: 1238\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset_dir = '/home/ml/datasets/price_tags/DANONE'\n",
    "# dataset_dir = '/home/ml/datasets/price_tags/EFKO'\n",
    "# dataset_dir = '/home/ml/datasets/price_tags/FERRERO'\n",
    "# dataset_dir = '/home/ml/datasets/price_tags/NESTLE'\n",
    "dataset_dir = '/home/ml/datasets/price_tags/SHWARZ'\n",
    "\n",
    "\n",
    "ann_dir = os.path.join(dataset_dir, 'anns')\n",
    "img_dir = os.path.join(dataset_dir, 'imgs')\n",
    "\n",
    "\n",
    "ann_paths = glob.glob(os.path.join(ann_dir, 'annotations_*.xml'))\n",
    "\n",
    "img_paths = []\n",
    "imgs = []\n",
    "anns = []\n",
    "files_not_found = []\n",
    "\n",
    "for ann_path in ann_paths:\n",
    "    \n",
    "    ann_info_list = parse_cvat(ann_path)\n",
    "    \n",
    "    for ann_info in ann_info_list:\n",
    "        img_path = os.path.join(img_dir, ann_info['filename'])\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            files_not_found.append(img_path)\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        ann = []\n",
    "        for i in ann_info['symbols']:\n",
    "            if i[0] == '%':\n",
    "                i[0] = 10\n",
    "            else:\n",
    "                i[0] = int(i[0])\n",
    "            ann.append(i)\n",
    "        for i in ann_info['rubs']:\n",
    "            i.insert(0, 11)\n",
    "            ann.append(i)\n",
    "        for i in ann_info['kops']:\n",
    "            i.insert(0, 12)\n",
    "            ann.append(i)\n",
    "        for i in ann_info['price_areas']:\n",
    "            i.insert(0, 13)\n",
    "            ann.append(i)\n",
    "        for i in ann_info['discount_areas']:\n",
    "            if i[0] == 'Horizontal':\n",
    "                i[0] = 14\n",
    "            elif i[0] == 'Vertical':\n",
    "                i[0] = 15\n",
    "            ann.append(i)\n",
    "        \n",
    "        img_paths.append(img_path)\n",
    "        imgs.append(img)\n",
    "        anns.append(ann)\n",
    "\n",
    "\n",
    "img_paths = np.array(img_paths)\n",
    "imgs = np.array(imgs)\n",
    "anns = np.array(anns)\n",
    "print(f'img_paths: {len(img_paths)}')\n",
    "print(f'imgs: {len(imgs)}')\n",
    "print(f'anns: {len(anns)}')\n",
    "print(f'\\nFILES NOT FOUND: {len(files_not_found)}')\n",
    "\n",
    "# ****************************************************\n",
    "print(f'\\n\\nMake unique!')\n",
    "img_paths, unique_img_idxs = np.unique(img_paths, return_index=True)\n",
    "imgs = imgs[unique_img_idxs]\n",
    "anns = anns[unique_img_idxs]\n",
    "print(f'unique img_paths: {len(img_paths)}')\n",
    "print(f'unique imgs: {len(imgs)}')\n",
    "print(f'unique anns: {len(anns)}')\n",
    "\n",
    "if len(imgs) != len(anns):\n",
    "    print('The lengths dont match !!!!!!!')\n",
    "\n",
    "# ****************************************************\n",
    "print(f'\\n\\nFilter empty anns!')\n",
    "empty_anns = np.array([True if len(a) == 0 else False for a in anns])\n",
    "print(f'empty anns: {np.count_nonzero(empty_anns)}')\n",
    "f = ~empty_anns\n",
    "img_paths = img_paths[f]\n",
    "imgs = imgs[f]\n",
    "anns = anns[f]\n",
    "print(f'img_paths: {len(img_paths)}')\n",
    "print(f'imgs: {len(imgs)}')\n",
    "print(f'anns: {len(anns)}')\n",
    "# ****************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(dataset_dir + '_filenames.npy', img_paths)\n",
    "# np.save(dataset_dir + '_images.npy', imgs)\n",
    "# np.save(dataset_dir + '_annotations.npy', anns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_stop = slice(0,200)\n",
    "# start_stop = np.random.randint(len(img_paths), size=200)\n",
    "\n",
    "for img_path, img, ann in zip(img_paths[start_stop], imgs[start_stop], anns[start_stop]):\n",
    "    print(img_path)\n",
    "    \n",
    "    draw_inference(img,\n",
    "         products_list=[ann],\n",
    "#          titles=['gt'],\n",
    "         titles=[os.path.basename(img_path)],\n",
    "         show=True,\n",
    "         plot_size=500,\n",
    "         dpi=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
